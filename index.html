<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1;charset=utf-8" />
	
<link rel="stylesheet" href="index.css" type="text/css" />
<title>Liang's Homepage</title>
<meta name="description" content="Website for Liang's Homepage">
</head>
<body>
	
<div class="container"> 
  <!-- Navigation -->
  <header class="header" >
    <nav>
      <ul>
        <li><a href="#homepage">Home</a></li>
        <li><a href="#News">News</a></li>
        <li><a href="#Publications">Publication</a></li>
        <li> <a href="#Activities">Activities</a></li>
      </ul>
    </nav>
</header>
	
<br />
<section id="homepage">
<table class="imgtable"><tr><td>
<img class="people-pic" src="./Liang.jpg" alt="Liang Liao"/></td>
<td align="left"><h1>Liang Liao (廖良)</h1>
<h4>Research Fellow, S-lab, Nanyang Technological University </h4>
<p>I am currently working with Prof. <a  href="https://personal.ntu.edu.sg/wslin/" class="person_link" target="_blank">Weisi Lin</a> as a Research Fellow at Nanyang Technological University (南洋理工大学). Before this, I worked with Prof. <a  href="http://www.satoh-lab.nii.ac.jp/" class="person_link" target="_blank">Shin'ichi Satoh</a> as a postdoctoral researcher at the National Institute of Informatics (国立情報学研究所), Japan. I received my Ph.D. degree at National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University (武汉大学) with honors in Jun. 2019, advised by Prof. <a  href="https://web.xidian.edu.cn/rmhu/" class="person_link" target="_blank">Ruimin Hu</a>. I received my B.Eng. degree at the International School of Software, Wuhan University in Jun. 2013. My research interests focus on visual signal coding, restoration, and understanding, particularly its applications to video compression, image inpainting, low-quality image analysis, and video quality assessment. 
<br />
<b>E-mail</b>: liang.liao AT ntu.edu.sg; <a href="https://scholar.google.com/citations?user=kqTUHSIAAAAJ&amp;hl=zh-CN" class="link" target="_blank">Google Scholar</a></p>
</td></tr></table>
	
<section id="News">	
<div class="infoblock">
<div class="blockcontent">
<h2>News</h2>
<ul>
<li><p>Jul., 2023 - <b>Call for Papers:</b> Submission Deadline: <b>Jul. 31, 2023</b>. <a  href="https://hpcn.exeter.ac.uk/isci2023/" class="link" target="_blank"><i>The 11th IEEE International Conference on Smart City and Informatization (iSCI-2023)</i></a>. Looking forward to seeing you in Exeter, UK.
</p>
</li>
<li><p>Jul., 2023 - I am serving as the Publicity Co-Chair of <i>iSCI 2023</i>, which will be held in Exeter, UK, 1-3 November 2023
</p>
</li>
<li><p>Jun., 2023 - One paper about audio-driven video frame interpolation is accepted by <i>ICIP 2023</i>
</p>
</li>
<li><p>Mar., 2023 - One paper about video quality assessment is accepted by <i>ICME 2023</i>
</p>
</li>
<li><p>Feb., 2023 - One paper about multi-view clustering is accepted by <i>CVPR 2023</i>
</p>
</li>
<li><p>Feb., 2023 - One paper about video quality assessment is accepted by <i>TCSVT</i>
</p>
</li>
<li><p>Feb., 2023 - One paper about high temporal frequency vehicle counting is accepted by <i>ISPRS Journal of Photogrammetry and Remote Sensing</i>
</p>
</li>
<li><p>Feb., 2023 - One paper about multi-target domain adaptation is accepted by <i>ICASSP 2023</i>
</p>
</li>	
<li><p>Jan., 2023 - One paper about disentangled representation learning is accepted by <i>CAAI Artificial Intelligence Research</i>
</p>
</li>
<li><p>Dec., 2022 - Two papers are accepted by <i>TMM</i> and <i>CAAI Transactions on Intelligence Technology</i>, respectively
</p>
</li>
<li><p>Nov., 2022 - <b>Call for Papers:</b> Submission Deadline: <b>Dec. 15, 2022</b>. <i>ICME 2023</i> Special Session on "<a  href="https://uolmm.github.io/ICME23SS/" class="link" target="_blank">Quality Enhancement and Assessment for Low-quality Multimedia Data Understanding</a>"
</p>
</li>
<li><p>Nov., 2022 - <b>Call for Papers:</b> Submission Deadline: <b>Jun. 1, 2023</b>. <i>Multimedia Tools and Applications</i> Special Issue on "<a href="https://www.springer.com/journal/11042/updates/23782752" class="link" target="_blank">Enhancement, Understanding and Assessment of Low-quality Multimedia Data</a>"
</p>
</li>
<li><p>Nov., 2022 - One paper about scene understanding under adverse weather is accepted by AAAI 2023
</p>
</li>		
<li><p>Jul., 2022 - <b>Call for Papers:</b> Submission Deadline: <b>Feb. 28, 2023</b>. <i>Applied Sciences</i> Special Issue on "<a  href="https://www.mdpi.com/journal/applsci/special_issues/23L188650Q" class="link" target="_blank">Recent Advances in Image Processing</a>"
</p>
</li>	
<li><p>Jul., 2022 - Four papers are accepted by ACM MM 2022, ECCV 2022, and ICIP 2022, respectively</p>
</li>
<li><p>Apr., 2022 - We are honored to invite three IEEE Fellows from academia and the Executive R&D Director from SenseBrain as the Keynote Speakers</p>
</li>
<li><p>Apr., 2022 - We are hosting an ACM MM 2022 Workshop. Details please refer to our <a  href="https://uolmm.github.io/Workshop/" class="link" target="_blank">Website </a></p>
</li>	
<li><p>Apr., 2022 - One paper about scene understanding under adverse weather is accepted by TIP</p>
</li>
 <li><p>Mar., 2022 - One paper about space-time video super-resolution is accepted by CVPR 2022</p>
</li>
<li><p>Feb., 2022 - I started as a Research Fellow at S-lab, Nanyang Technological University</p>
</li>
<li><p>Jan., 2022 - The personal website is online (Github)</p>
</li>
<li><p>Oct., 2019 - I started as a post-doctor at National Institute of Informatics, Japan</p>
</li>
<li><p>Jun., 2019 - I got PHD degree from Wuhan University</p>
</li>
<br />
</ul>
</div>
</div>
<section id="Publications">	
	
<h2>Publications (* Corresponding Author)</h2>
<h3>Preprints</h3>

<ul>
<li><p class="title"><a href="https://arxiv.org/abs/2306.11528" target="_blank">TransRef: Multi-Scale Reference Embedding Transformer for Reference-Guided Image Inpainting
</a></p>
	<p><b>Liang Liao</b>, Taorong Liu, Delin Chen, Jing Xiao, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>arXiv:2306.11528</b></i></p>
</li>
<li><p class="title"><a href="https://arxiv.org/abs/2305.12726" target="_blank">Towards Explainable In-the-Wild Video Quality Assessment: a Database and a Language-Prompted Approach
</a></p>
	<p>Haoning Wu, Erli Zhang, <b>Liang Liao</b>, Chaofeng Chen, Jingwen Hou, Annan Wang, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>arXiv:2305.12726</b></i></p>
</li>	
<li><p class="title"><a href="https://arxiv.org/abs/2304.14672" target="_blank">Towards Robust Text-Prompted Semantic Criterion for In-the-Wild Video Quality Assessment
</a></p>
	<p>Haoning Wu, <b>Liang Liao</b>, Annan Wang, Chaofeng Chen, Jingwen Hou, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>arXiv:2304.14672</b></i></p>
</li>		
<li><p class="title"><a href="https://arxiv.org/abs/2210.05357" target="_blank">Neighbourhood Representative Sampling for Efficient End-to-end Video Quality Assessment
</a></p>
	<p>Haoning Wu, Chaofeng Chen, <b>Liang Liao</b>, Jingwen Hou, Wenxiu Sun, Qiong Yan, Jinwei Gu and Weisi Lin</p>
	<p> <i><b>arXiv:2210.05357</b></i></p>
</li>	
<li><p class="title"><a href="https://arxiv.org/abs/2211.04894" target="_blank">Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives
</a></p>
	<p>Haoning Wu#, Erli Zhang#, <b>Liang Liao#</b>, Chaofeng Chen, Jingwen Hou, Annan Wang, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>arXiv:2211.04894</b></i></p>
</li>

	
</ul>	
<h3>2023</h3>
<ul>
<li><p class="title">ASVFI: Audio-driven Speaker Video Frame Interpolation</p>
	<p>Qianrui Wang, Dengshi Li, <b>Liang Liao</b>, Hao Song, Wei Li, and Jing Xiao</p>
	<p> <i><b>ICIP 2023</b></i> (Accepted)</p>
</li>	
<li><p class="title">Exploring Opinion-Unaware Video Quality Assessment with Semantic Affinity Criterion</p>
	<p>Haoning Wu, <b>Liang Liao</b>, Jingwen Hou, Chaofeng Chen, Erli Zhang, Annan Wang, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>ICME 2023</b></i></p>
</li>
<li><p class="title">GCFAgg: Global and Cross-view Feature Aggregation for Multi-view Clustering</p>
	<p>Weiqing Yan, Yuanyang Zhang, Chenlei Lv, Chang Tang, Guanghui Yue, <b>Liang Liao</b>, and Weisi Lin</p>
	<p> <i><b>CVPR 2023</b></i></p>
</li>
<li><p class="title"><a href="https://arxiv.org/abs/2206.09853" target="_blank">DisCoVQA: Temporal Distortion-Content Transformers for Video Quality Assessment
</a></p>
	<p>Haoning Wu, Chaofeng Chen, <b>Liang Liao</b>, Jingwen Hou, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>TCSVT 2023</b></i></p>
</li>	
<li><p class="title">High Temporal Frequency Vehicle Counting from Low-Resolution Satellite Images</p>
	<p><b>Liang Liao</b>, Jing Xiao, Yan Yang, Xujie Ma, Zheng Wang, and Shin'ichi Satoh</p>
	<p> <i><b>ISPRS Journal of Photogrammetry and Remote Sensing 2023</b></i></p>
</li>	
<li><p class="title">BAT: Bi-Alignment Based on Transformation in Multi-Target Domain Adaptation for Semantic Segmentation</p>
	<p>Xian Zhong, Wei Li, <b>Liang Liao*</b>, Jing Xiao, Wenxuan Liu, Wenxin Huang, and Zheng Wang</p>
	<p> <i><b>ICASSP 2023</b></i></p>
</li>
<li><p class="title">A Review of Disentangled Representation Learning for Remote Sensing Data</p>
	<p>Mi Wang, Huiwen Wang, Jing Xiao, <b>Liang Liao</b></p>
	<p> <i><b>CAAI Artificial Intelligence Research 2023</b></i></p>
</li>	
<li><p class="title">Progressive Motion Boosting for Video Frame Interpolation</p>
	<p>Jing Xiao, Kangmin Xu, Mengshun Hu, <b>Liang Liao*</b>, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>TMM 2023</b></i></p>
</li>		
<li><p class="title">OSAP-Loss: Efficient Optimization of Average Precision via Involving Samples after Positive Ones Towards Remote Sensing Image Retrieval</p>
	<p>Xin Yuan, Xin Xu, Xiao Wang, Kai Zhang, <b>Liang Liao</b>, Zheng Wang, and Chia-Wen Lin</p>
	<p> <i><b>CAAI Transactions on Intelligence Technology 2023</b></i></p>
</li>	
	
<li><p class="title">Only a Few Classes Confusing: Pixel-wise Candidate Labels Disambiguation for Foggy Scene Understanding</p>
	<p><b>Liang Liao</b>, Wenyi Chen, Zhen Zhang, Jing Xiao, Yan Yang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>AAAI 2023</b></i></p>
</li>	
</ul>	
<h3>2022</h3>
<ul>
<li><p class="title"><a href="https://arxiv.org/abs/2207.02595" target="_blank">FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling
</a></p>
	<p>	Haoning Wu, Chaofeng Chen, Jingwen Hou, <b>Liang Liao</b>, Annan Wang, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>ECCV 2022</b></i></p>
</li>	
	
<li><p class="title"><a href="https://arxiv.org/abs/2207.03723" target="_blank">Exploring the Effectiveness of Video Perceptual Representation in Blind Video Quality Assessment</a></p>
	<p>	<b>Liang Liao</b>, Kangmin Xu, Haoning Wu, Chaofeng Chen, Wenxiu Sun, Qiong Yan, and Weisi Lin</p>
	<p> <i><b>ACM MM 2022</b></i></p>
</li>	
	
<li><p class="title">Progressive Spatial-temporal Collaborative Network for Video Frame Interpolation</p>
	<p>	Mengshun Hu, Kui Jiang, <b>Liang Liao</b>, Zhixiang Nie, Jing Xiao, and Zheng Wang</p>
	<p> <i><b>ACM MM 2022</b></i></p>
</li>	
	
<li><p class="title"><a href="https://arxiv.org/abs/2207.14498" target="_blank">Reference-guided Texture and Structure Inference for Image Inpainting</a></p>
	<p>	Taorong Liu, <b>Liang Liao*</b>, Zheng Wang, and Shin'ichi Satoh</p>
	<p> <i><b>ICIP 2022</b></i></p>
</li>
	
<li><p class="title"><a href="https://ieeexplore.ieee.org/document/9771097" target="_blank">Unsupervised Foggy Scene Understanding via Self Spatial-Temporal Label Diffusion</a></p>
	<p>	<b>Liang Liao</b>, Wenyi Chen, Jing Xiao, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>TIP 2022</b></i></p>
</li>
<li><p class="title"><a href="https://arxiv.org/abs/2205.05264" target="_blank">Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning</a></p>
	<p>	Mengshun Hu, Kui Jiang, <b>Liang Liao</b>, Jing Xiao, Junjun Jiang, and Zheng Wang</p>
	<p> <i><b>CVPR 2022</b></i></p>
</li>	
<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/9722832" target="_blank">Weakly-supervised Learning with Complementary Heatmap for Retinal Disease Detection</a></p>
	<p>	Qier Meng, <b>Liang Liao*</b>, and Shin'ichi Satoh</p>
	<p> <i><b>TMI 2022</b></i></p>
</li>
<li><p class="title"><a  href="https://ieeexplore.ieee.org/abstract/document/9530577" target="_blank">Capturing Small, Fast-Moving Objects: Frame Interpolation via Recurrent Motion Enhancement</a></p>
	<p>	Mengshun Hu, Jing Xiao, <b>Liang Liao*</b>, Zheng Wang, Chia-Wen Lin, Mi Wang and Shin'ichi Satoh</p>
	<p> <i><b>TCSVT 2022</b></i></p>
</li>
<li><p class="title"><a  href="http://www.cjig.cn/jig/ch/reader/view_abstract.aspx?edit_id=20220526113528001&file_no=202112310000003" target="_blank">面向视觉数据处理与分析的解耦表示学习综述</a></p>
	<p>	李雅婷，肖晶， <b>廖良</b>，王正，王密</p>
	<p> <i><b>中国图象图形学报学报 2022</b></i></p>
</li>
	</ul>
<h3>Before 2022</h3>
<ul>
<li><p class="title"><a  href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liao_Image_Inpainting_Guided_by_Coherence_Priors_of_Semantics_and_Textures_CVPR_2021_paper.pdf" target="_blank">Image Inpainting Guided by Coherence Priors of Semantics and Textures</a></p>
	<p><b>Liang Liao</b>, Jing Xiao, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>CVPR 2021</b></i></p>
</li>	
<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/9296949" target="_blank">Uncertainty-Aware Semantic Guidance and Estimation for Image Inpainting</a></p>
	<p><b>Liang Liao</b>, Jing Xiao, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>JSTSP 2021</b></i></p>
</li>	
<li><p class="title"><a  href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720681.pdf" target="_blank">Guidance and Evaluation: Semantic-Aware Image Inpainting for Mixed Scenes</a></p>
	<p><b>Liang Liao</b>, Jing Xiao, Zheng Wang, Chia-Wen Lin, and Shin'ichi Satoh</p>
	<p> <i><b>ECCV 2020</b></i></p>
</li>	

<li><p class="title"><a  href="https://www.mdpi.com/2072-4292/12/3/497" target="_blank">Learned Representation of Satellite Image Series for Data Compression</a></p>
	<p><b>Liang Liao</b>, Jing Xiao, Yating Li, Mi Wang, and Ruimin Hu</p>
	<p> <i><b>Remote Sensing 2020</b></i></p>
</li>	
<li><p class="title"><a  href="https://ieeexplore.ieee.org/abstract/document/9053223" target="_blank">Motion Feedback Design for Video Frame Interpolation
</a></p>
	<p>Mengshun Hu, <b>Liang Liao</b>, Jing Xiao, Lin Gu, and Shin'ichi Satoh</p>
	<p> <i><b>ICASSP 2020</b></i></p>
</li>
<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/8669751" target="_blank">Artist-Net: Decorating the Inferred Content With Unified Style for Image Inpainting</a></p>
	<p><b>Liang Liao</b>, Ruimin Hu, Jing Xiao, and Zhongyuan Wang</p>
	<p> <i><b>IEEE Access 2019</b></i></p>
</li>			
<li><p class="title"><a  href="https://ojs.aaai.org/index.php/AAAI/article/view/3805" target="_blank">CISI-net: Explicit latent content inference and imitated style rendering for image inpainting</a></p>
	<p>Jing Xiao, <b>Liang Liao*</b>, Qiegen Liu, and Ruimin Hu</p>
	<p> <i><b>AAAI 2019</b></i></p>
</li>
<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/8462549" target="_blank">Edge-Aware Context Encoder for Image Inpainting</a></p>
	<p><b>Liang Liao</b>, Ruimin Hu, Jing Xiao, and Zhongyuan Wang</p>
	<p> <i><b>ICASSP 2018</b></i></p>
</li>
<li><p class="title"><a  href="https://link.springer.com/chapter/10.1007/978-3-319-48896-7_42" target="_blank">An Analysis-Oriented ROI Based Coding Approach on Surveillance Video Data</a></p>
	<p><b>Liang Liao</b>, Ruimin Hu, Jing Xiao, Gen Zhan, Yu Chen, and Jun Xiao</p>
	<p> <i><b>PCM 2016</b></i></p>
</li>
<li><p class="title"><a  href="https://link.springer.com/chapter/10.1007/978-3-319-48890-5_48" target="_blank">Criminal Investigation Oriented Saliency Detection for Surveillance Videos
</a></p>
	<p>Yu Chen, Ruimin Hu, Jing Xiao, <b>Liang Liao</b>, Jun Xiao, and Gen Zhan</p>
	<p> <i><b>PCM 2016</b></i></p>
</li>
<li><p class="title"><a  href="https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2430" target="_blank">A sensitive object-oriented approach to big surveillance data compression for social security applications in smart cities
</a></p>
	<p>Jing Xiao, Zhongyuan Wang, Yu Chen, <b>Liang Liao</b>, Jun Xiao, Gen Zhan, and Ruimin Hu</p>
	<p> <i><b>Software: Practice and Experience 2016</b></i></p>
</li>
<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/7492295" target="_blank">Knowledge-based Coding of Objects for Multi-source Surveillance Video Data</a></p>
	<p>Jing Xiao, Ruimin Hu, <b>Liang Liao</b>, Yu Chen, Zhongyuan Wang, and Zixiang Xiong</p>
	<p> <i><b>TMM 2016</b></i></p>
</li>

<li><p class="title"><a  href="https://ieeexplore.ieee.org/document/7350898" target="_blank">Exploiting Effects of Parts in Fine-grained Categorization of Vehicles</a></p>
	<p><b>Liang Liao</b>, Ruimin Hu, Jing Xiao, Qi Wang, Jun Xiao, and Jun Chen</p>
	<p> <i><b>ICIP 2015</b></i></p>
</li>
<li><p class="title"><a  href="https://link.springer.com/article/10.1007/s10586-015-0434-z" target="_blank">Exploiting global redundancy in big surveillance video data for efficient coding
</a></p>
	<p>Jing Xiao, <b>Liang Liao</b>, Jinhui Hu, Yu Chen, and Ruimin Hu</p>
	<p> <i><b>Cluster Computing 2015</b></i></p>
</li>
<li><p class="title"><a  href="https://link.springer.com/chapter/10.1007/978-3-319-24075-6_68" target="_blank">Non-overlapped Multi-source Surveillance Video Coding Using Two-Layer Knowledge Dictionary
</a></p>
	<p>Yu Chen, Jing Xiao, <b>Liang Liao</b>, and Ruimin Hu</p>
	<p> <i><b>PCM 2015</b></i></p>
</li>
<li><p class="title"><a  href="https://ieeexplore.ieee.org/abstract/document/7149260" target="_blank">Global coding of multi-source surveillance video data</a></p>
	<p>Jing Xiao, Yu Chen, <b>Liang Liao</b>, Jinhui Hu, and Ruimin Hu</p>
	<p> <i><b>DCC 2015</b></i></p>
</li>
	</ul>

<section id="Activities">
<h2>Professional Activities</h2>
<ul>
<li><p>Publicity Co-Chair of <a  href="https://hpcn.exeter.ac.uk/isci2023/" class="link" target="_blank"><i>The 11th IEEE International Conference on Smart City and Informatization</i></a>, which will be held in Exeter, UK, 1-3 November 2023</p>
</li>
<li><p>Chair of <i>ICME 2023</i> Special Session &ldquo;<a  href="https://uolmm.github.io/ICME23SS/" class="link" target="_blank">Quality Enhancement and Assessment for Low-quality Multimedia Data Understanding</a>&rdquo;</p>
</li>
<li><p>Lead Guest Editor of <i>Multimedia Tools and Applications</i> Special Issue on &ldquo;<a href="https://www.springer.com/journal/11042/updates/23782752" class="link" target="_blank">Enhancement, Understanding and Assessment of Low-quality Multimedia Data</a>&rdquo;</p>
</li>
<li><p>Guest Editor of <i>Applied Sciences</i> Special Issue on &ldquo;<a  href="https://www.mdpi.com/journal/applsci/special_issues/23L188650Q" class="link" target="_blank">Recent Advances in Image Processing</a>&rdquo;</p>
</li>
<li><p>Chair of <i>ACM MM 2022</i> Workshop &ldquo;<a  href="https://uolmm.github.io/Workshop/" class="link" target="_blank">UoLMM - Robust Understanding of Low-quality Multimedia Data: Unitive Enhancement, Analysis, and Evaluation</a>&rdquo;</p>
</li>
<li><p>Co-chair of <i>ICME 2022</i> Special Session &ldquo;<a  href="https://guangweigao.github.io/icme22ss.html" class="link" target="_blank">Robust Representation Learning for Multimedia Image Understanding</a>&rdquo;</p>
</li>
<li><p>Co-chair of <i>ACM MM Asia 2021</i> Workshop &ldquo;<a  href="https://workshopcv.github.io/" class="link" target="_blank">Visual Tasks and Challenges under Low-quality Media Data</a>&rdquo;</p>
</li>
<li><p>Served as a reviewer for journals and conferences including TIP, TMM, TCSVT, TNNLS, ICML, NeurIPS, ICLR, CVPR, ICCV, ECCV, ACM MM, AAAI, etc.</p>
</li>
<li><p>Served as the chair of Graduate Student Forum of National Research Center for Multimedia Software Technology, Wuhan University (2014.07-2015.12).</p>
</li>
<li><p>Won the Bronze Prize of the 5th China Internet+ Innovation and Entrepreneurship Competition.</p>
</li>
<li><p>Awarded the Second Prize of Academic Innovation of Wuhan University in 2019</p>
</li>
</ul>
	
<br />	
</body>
</html>
